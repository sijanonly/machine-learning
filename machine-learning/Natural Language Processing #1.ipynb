{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing 'The Natural Language Toolkit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Use News corpus for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brown_train = brown.tagged_sents(categories='news')\n",
    "regexp_tagger = nltk.RegexpTagger(\n",
    "    [(r'^-?[0-9]+(.[0-9]+)?$', 'CD'),\n",
    "     (r'(-|:|;)$', ':'),\n",
    "     (r'\\'*$', 'MD'),\n",
    "     (r'(The|the|A|a|An|an)$', 'AT'),\n",
    "     (r'.*able$', 'JJ'),\n",
    "     (r'^[A-Z].*$', 'NNP'),\n",
    "     (r'.*ness$', 'NN'),\n",
    "     (r'.*ly$', 'RB'),\n",
    "     (r'.*s$', 'NNS'),\n",
    "     (r'.*ing$', 'VBG'),\n",
    "     (r'.*ed$', 'VBD'),\n",
    "     (r'.*', 'NN')\n",
    "])\n",
    "unigram_tagger = nltk.UnigramTagger(brown_train, backoff=regexp_tagger)\n",
    "bigram_tagger = nltk.BigramTagger(brown_train, backoff=unigram_tagger)\n",
    "\n",
    "cfg = {}\n",
    "cfg[\"NNP+NNP\"] = \"NNP\"\n",
    "cfg[\"NN+NN\"] = \"NNI\"\n",
    "cfg[\"NNI+NN\"] = \"NNI\"\n",
    "cfg[\"JJ+JJ\"] = \"JJ\"\n",
    "cfg[\"JJ+NN\"] = \"NNI\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a Extraction class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NPExtractor(object):\n",
    "\n",
    "    def __init__(self, sentence):\n",
    "        self.sentence = sentence\n",
    "\n",
    "    # Split the sentence into singlw words/tokens\n",
    "    def tokenize_sentence(self, sentence):\n",
    "        tokens = nltk.word_tokenize(sentence)\n",
    "        return tokens\n",
    "\n",
    "    # Normalize brown corpus' tags (\"NN\", \"NN-PL\", \"NNS\" > \"NN\")\n",
    "    def normalize_tags(self, tagged):\n",
    "        n_tagged = []\n",
    "        for t in tagged:\n",
    "            if t[1] == \"NP-TL\" or t[1] == \"NP\":\n",
    "                n_tagged.append((t[0], \"NNP\"))\n",
    "                continue\n",
    "            if t[1].endswith(\"-TL\"):\n",
    "                n_tagged.append((t[0], t[1][:-3]))\n",
    "                continue\n",
    "            if t[1].endswith(\"S\"):\n",
    "                n_tagged.append((t[0], t[1][:-1]))\n",
    "                continue\n",
    "            n_tagged.append((t[0], t[1]))\n",
    "        return n_tagged\n",
    "\n",
    "    # Extract the main topics from the sentence\n",
    "    def extract(self):\n",
    "\n",
    "        tokens = self.tokenize_sentence(self.sentence)\n",
    "        tags = self.normalize_tags(bigram_tagger.tag(tokens))\n",
    "\n",
    "        merge = True\n",
    "        while merge:\n",
    "            merge = False\n",
    "            for x in range(0, len(tags) - 1):\n",
    "                t1 = tags[x]\n",
    "                t2 = tags[x + 1]\n",
    "                key = \"%s+%s\" % (t1[1], t2[1])\n",
    "                value = cfg.get(key, '')\n",
    "                if value:\n",
    "                    merge = True\n",
    "                    tags.pop(x)\n",
    "                    tags.pop(x)\n",
    "                    match = \"%s %s\" % (t1[0], t2[0])\n",
    "                    pos = value\n",
    "                    tags.insert(x, (match, pos))\n",
    "                    break\n",
    "\n",
    "        matches = []\n",
    "        for t in tags:\n",
    "            if t[1] == \"NNP\" or t[1] == \"NNI\":\n",
    "            #if t[1] == \"NNP\" or t[1] == \"NNI\" or t[1] == \"NN\":\n",
    "                matches.append(t[0])\n",
    "        return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
